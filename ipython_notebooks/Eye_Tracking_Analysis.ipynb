{
 "metadata": {
  "name": "",
  "signature": "sha256:5205c47647e292f4bd1e3d0bc56f7faacedda082a159ee71afddc43a47d65a4d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Eye Tracking and Knowledge"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import string\n",
      "import re\n",
      "import time\n",
      "import math\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.cross_validation import KFold\n",
      "from collections import defaultdict\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.feature_selection import RFE\n",
      "from sklearn.cluster import KMeans"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load gaze and pupil data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_gaze = pd.read_csv('../data/logsAndEye_09152014.csv', na_values=['None'])\n",
      "df_pupil = pd.read_csv('../data/pupilDiameters.csv', na_values=['None'])\n",
      "# df_pupil.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Join datasets on subject_sync and add meta features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# datasets are joined with rows containing null values dropped\n",
      "df_all_data = df_gaze.merge(df_pupil, on='subject_sync').set_index('subject_sync').dropna()\n",
      "\n",
      "# clean up column names (for pupil cols)\n",
      "clean_columns = [name.replace(\" \",\"_\").replace(\"[\",\"\").replace(\"]\",\"\") for name in df_all_data.columns]\n",
      "df_all_data.columns = clean_columns\n",
      "\n",
      "students = set(df_all_data.student)\n",
      "for s in students:\n",
      "    df_all_data[s] = df_all_data.apply(lambda x: 1 if x.student == s else 0, axis=1)\n",
      "    \n",
      "problems = set(df_all_data.problem)\n",
      "for p in problems:\n",
      "    df_all_data[p] = df_all_data.apply(lambda x: 1 if x.problem == p else 0, axis=1)\n",
      "    \n",
      "prob_types = set(df_all_data.problemType)\n",
      "for p in prob_types:\n",
      "    df_all_data[p] = df_all_data.apply(lambda x: 1 if x.problemType == p else 0, axis=1)\n",
      "\n",
      "units = ['U1', 'U2', 'U3']\n",
      "for u in units:\n",
      "    df_all_data[u] = df_all_data.apply(lambda x: 1 if u in x.problem else 0, axis=1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "K means clusters on Eye Tracking features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gaze_cols = [\n",
      " 'eye_switch',\n",
      " 'eye_2ndFixDur_GR',\n",
      " 'eye_2ndFixDur_Interactions',\n",
      " 'eye_2ndFixDur_Titles',\n",
      " 'eye_2ndFixDur_Hints', \n",
      " 'eye_2ndFixDur_Progress',\n",
      " 'eye_2ndFixDur_WhiteSpace',\n",
      " 'eye_1stFixDur_GR',\n",
      " 'eye_1stFixDur_Interactions',\n",
      " 'eye_1stFixDur_Titles',\n",
      " 'eye_1stFixDur_Hints',\n",
      " 'eye_1stFixDur_Progress',\n",
      " 'eye_1stFixDur_WhiteSpace',\n",
      " 'eye_fixDur_GR',\n",
      " 'eye_fixDur_Interactions',\n",
      " 'eye_fixDur_Titles',\n",
      " 'eye_fixDur_Hints', \n",
      " 'eye_fixDur_Progress',\n",
      " 'eye_fixDur_WhiteSpace',\n",
      " 'seq2_betweenGRs',\n",
      " 'seq2_autoGR',\n",
      " 'seq2_GR-caption',\n",
      " 'seq2_GR-Interactions',\n",
      " 'seq2_GR-HintText',\n",
      " 'seq2_GR-Progress',\n",
      " 'seq2_Interactions-Progress',\n",
      " 'seq2_Interactions-HintText',\n",
      " 'seq3_betweenGRs',\n",
      " 'seq3_autoGR', \n",
      " 'seq3_GR-caption-GR',\n",
      " 'seq3_caption-GR-caption',\n",
      " 'seq3_GR-Interactions-GR',\n",
      " 'seq3_Interactions-GR-Interactions',\n",
      " 'seq3_GR-HintText-GR',\n",
      " 'seq3_HintText-GR-HintText',\n",
      " 'seq3_Interactions-HintText-Interactions',\n",
      " 'seq3_HintText-Interactions-HintText',\n",
      " 'seq3_GR-Progress-GR',\n",
      " 'seq3_Progress-GR-Progress',\n",
      " 'seq3_Progress-Interactions-Progress']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_gaze_features = df_all_data[gaze_cols]\n",
      "df_cluster_features = pd.DataFrame(index=df_gaze_features.index)\n",
      "df_gaze_features = StandardScaler().fit_transform(df_gaze_features)\n",
      "\n",
      "for n in xrange(2,9):\n",
      "    k_means = KMeans(init='k-means++', n_clusters=n, n_init=10)\n",
      "    k_means.fit(df_gaze_features)\n",
      "    k_means_labels = k_means.labels_\n",
      "    k_means_cluster_centers = k_means.cluster_centers_\n",
      "    k_means_labels_unique = np.unique(k_means_labels)\n",
      "    \n",
      "    #create dataframe with cluster\n",
      "    for cluster in xrange(n):\n",
      "        label = 'k%d_%d' % (n, cluster)\n",
      "        df_cluster_features[label] = [1 if x == cluster else 0 for x in k_means_labels]\n",
      "        \n",
      "df_all_data = df_all_data.join(df_cluster_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_features = list(df_cluster_features.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fill in values for meta features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(sorted(df_all_data.logs_firstCorrectRate))[821:]\n",
      "# (sorted(df_all_data.logs_firstCorrectRate))[820:]\n",
      "\n",
      "# 0.61538461499999997\n",
      "# 0.78260869599999994\n",
      "\n",
      "def assign_class(percent):\n",
      "    if percent < 0.63: #0.61538461499999997:\n",
      "        return 1\n",
      "#     elif (percent < 0.78260869599999994) & (percent > 0.61538461499999997):    \n",
      "    elif (percent < 0.80) & (percent >= 0.63):\n",
      "        return 2\n",
      "    else:\n",
      "        return 3 \n",
      "    \n",
      "df_all_data['firstCorrectThirdSplit'] = df_all_data.logs_firstCorrectRate.apply(assign_class)\n",
      "\n",
      "df_all_data.firstCorrectThirdSplit.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "2    446\n",
        "1    422\n",
        "3    366\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#max likely class\n",
      "446.0/1234"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "0.36142625607779577"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# list of all columns\n",
      "# [col for col in df_all_data.chem2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# FEATURE SELECTION\n",
      "\n",
      "feature_cols = [\n",
      " 'logs_Correct',\n",
      " 'eye_switch',\n",
      " 'eye_2ndFixDur_GR',\n",
      " 'eye_2ndFixDur_Interactions',\n",
      " 'eye_2ndFixDur_Titles',\n",
      " 'eye_2ndFixDur_Hints', #\n",
      " 'eye_2ndFixDur_Progress',\n",
      " 'eye_2ndFixDur_WhiteSpace',\n",
      " 'eye_1stFixDur_GR',\n",
      " 'eye_1stFixDur_Interactions',\n",
      " 'eye_1stFixDur_Titles',\n",
      " 'eye_1stFixDur_Hints',\n",
      " 'eye_1stFixDur_Progress',\n",
      " 'eye_1stFixDur_WhiteSpace',\n",
      " 'eye_fixDur_GR',\n",
      " 'eye_fixDur_Interactions',\n",
      " 'eye_fixDur_Titles',\n",
      " 'eye_fixDur_Hints', #\n",
      " 'eye_fixDur_Progress',\n",
      " 'eye_fixDur_WhiteSpace',\n",
      " 'seq2_betweenGRs',\n",
      " 'seq2_autoGR',\n",
      " 'seq2_GR-caption',\n",
      " 'seq2_GR-Interactions',\n",
      " 'seq2_GR-HintText',\n",
      " 'seq2_GR-Progress',\n",
      " 'seq2_Interactions-Progress',\n",
      " 'seq2_Interactions-HintText',\n",
      " 'seq3_betweenGRs',\n",
      " 'seq3_autoGR', #\n",
      " 'seq3_GR-caption-GR',\n",
      " 'seq3_caption-GR-caption',\n",
      " 'seq3_GR-Interactions-GR',\n",
      " 'seq3_Interactions-GR-Interactions',\n",
      " 'seq3_GR-HintText-GR',\n",
      " 'seq3_HintText-GR-HintText',\n",
      " 'seq3_Interactions-HintText-Interactions',\n",
      " 'seq3_HintText-Interactions-HintText',\n",
      " 'seq3_GR-Progress-GR',\n",
      " 'seq3_Progress-GR-Progress',\n",
      " 'seq3_Progress-Interactions-Progress',\n",
      " 'pretest_sense',\n",
      "#  'posttest1_sense',\n",
      "#  'posttest2_sense',\n",
      " 'pretest_fluency',\n",
      "#  'posttest1_fluency',\n",
      "#  'posttest2_fluency',\n",
      " 'pretest_concScales',\n",
      "#  'posttest1_concScales',\n",
      "#  'posttest2_concScales',\n",
      "#  'prePost_concScales',\n",
      " 'Average_Pupil_Diameter_mm',\n",
      " 'AveragePupil_Size_px_X']\n",
      "\n",
      "#choose an outcome variable\n",
      "outcome_col = 'firstCorrectThirdSplit'\n",
      "# outcome_col = 'logs_errorRate_medianSplit' \n",
      "# oucome_col = 'logs_firstIncorrectRate_medianSplit'\n",
      "\n",
      "other_features = [\n",
      " 'logs_Correct',\n",
      " 'pretest_sense',\n",
      " 'pretest_fluency',\n",
      " 'pretest_concScales',\n",
      " 'Average_Pupil_Diameter_mm',\n",
      " 'AveragePupil_Size_px_X']\n",
      "\n",
      "all_feature_cols = list(students) + list(problems) + list(prob_types) + units + cluster_features + other_features\n",
      "\n",
      "df_features = df_all_data[all_feature_cols]\n",
      "len(df_features.columns)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "166"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# df_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross-validation function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cross-Validation Function\n",
      "def cv_fun(pipeline):\n",
      "    scores = []\n",
      "    for train_idx, cv_idx in KFold(n=len(df_features), n_folds=8, indices=False, shuffle=True):\n",
      "        train_features = df_features[train_idx]\n",
      "        train_y    = np.asarray(df_all_data[train_idx][outcome_col])\n",
      "        test_features  = df_features[cv_idx]\n",
      "        test_y     = np.asarray(list(df_all_data[cv_idx][outcome_col]))\n",
      "        pipeline.fit(train_features, train_y)\n",
      "        score = pipeline.score(test_features, test_y)    \n",
      "        scores.append(score)\n",
      "    return scores, np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification pipelines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nb(df_train):\n",
      "    pipeline = Pipeline([\n",
      "#         ('scaler', StandardScaler()),\n",
      "        ('clf', GaussianNB())\n",
      "    ])\n",
      "    result = cv_fun(pipeline=pipeline)\n",
      "    print \"NB average score:\", result[1]\n",
      "    print \"NB scores:\", result[0]\n",
      "    print \"stddev:\", np.std(result[0]) \n",
      "#     print \"range:\", np.max(result[0]) - np.min(result[0])\n",
      "    print\n",
      "    \n",
      "    \n",
      "def max_ent(df_train):\n",
      "    pipeline = Pipeline([\n",
      "#         ('scaler', StandardScaler()),\n",
      "        ('clf', LogisticRegression(penalty='l2'))\n",
      "    ])\n",
      "    result = cv_fun(pipeline=pipeline)\n",
      "    print \"MaxEnt average score:\", result[1]\n",
      "    print \"MaxEnt scores:\", result[0]\n",
      "    print \"stddev:\", np.std(result[0])\n",
      "#     print \"range:\", np.max(result[0]) - np.min(result[0])\n",
      "    print\n",
      "\n",
      "    \n",
      "def random_forest(df_train):\n",
      "    pipeline = Pipeline([\n",
      "        ('feature_selection', ExtraTreesClassifier()), # need way to print this, see which features picked\n",
      "        ('clf', RandomForestClassifier())\n",
      "    ])\n",
      "    result = cv_fun(pipeline=pipeline)\n",
      "    print \"RF average score:\", result[1]\n",
      "    print \"RF scores:\", result[0]\n",
      "    print \"stddev:\", np.std(result[0])\n",
      "#     print \"range:\", np.max(result[0]) - np.min(result[0])\n",
      "    print\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Evaluate scores across k folds\n",
      "\n",
      "nb(df_features)\n",
      "max_ent(df_features)\n",
      "random_forest(df_features) #(rf_feature_cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NB average score: 0.480498533724\n",
        "NB scores: [0.50967741935483868, 0.5161290322580645, 0.44155844155844154, 0.4935064935064935, 0.47402597402597402, 0.44155844155844154, 0.46753246753246752, 0.5]\n",
        "stddev: 0.0271871487433\n",
        "\n",
        "MaxEnt average score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.580168621701\n",
        "MaxEnt scores: [0.63225806451612898, 0.59999999999999998, 0.57792207792207795, 0.6428571428571429, 0.57792207792207795, 0.5, 0.54545454545454541, 0.56493506493506496]\n",
        "stddev: 0.0431721473688\n",
        "\n",
        "RF average score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.529241726016\n",
        "RF scores: [0.47096774193548385, 0.50322580645161286, 0.55194805194805197, 0.5, 0.55844155844155841, 0.5714285714285714, 0.59090909090909094, 0.48701298701298701]\n",
        "stddev: 0.0413246770999\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Research Questions\n",
      "\n",
      "1. What are the features of eye tracking that best predict performance? \n",
      "\n",
      "2. Multiple representations of concepts were provided within the tutor. Can an analysis make recommendations about the efficacy of each representation?\n",
      "\n",
      "3. Can we predict learning (Post-Pre knowledge) from eye tracking features?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Next TODOs:\n",
      "\n",
      "# Go back and inspect which rows were dropped with dropna(). Other outliers we need to take care of?\n",
      "\n",
      "# Improve feature selection to find most informative features\n",
      "# http://scikit-learn.org/stable/modules/feature_selection.html\n",
      "\n",
      "# problem type, unit, problem, student\n",
      "# 3 bins for outcome\n",
      "\n",
      "#predictive ability of pretest for top vs bottom?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # Refining Random Forest features\n",
      "\n",
      "# rf_feature_cols = [\n",
      "#  'logs_Correct',\n",
      "#  'eye_switch',\n",
      "#  'eye_2ndFixDur_GR',\n",
      "#  'eye_2ndFixDur_Interactions',\n",
      "#  'eye_2ndFixDur_Titles',\n",
      "# #  'eye_2ndFixDur_Hints', #\n",
      "#  'eye_2ndFixDur_Progress',\n",
      "#  'eye_2ndFixDur_WhiteSpace',\n",
      "#  'eye_1stFixDur_GR',\n",
      "#  'eye_1stFixDur_Interactions',\n",
      "#  'eye_1stFixDur_Titles',\n",
      "#  'eye_1stFixDur_Hints',\n",
      "#  'eye_1stFixDur_Progress',\n",
      "#  'eye_1stFixDur_WhiteSpace',\n",
      "#  'eye_fixDur_GR',\n",
      "#  'eye_fixDur_Interactions',\n",
      "#  'eye_fixDur_Titles',\n",
      "# #  'eye_fixDur_Hints', #\n",
      "#  'eye_fixDur_Progress',\n",
      "#  'eye_fixDur_WhiteSpace',\n",
      "#  'seq2_betweenGRs',\n",
      "#  'seq2_autoGR',\n",
      "#  'seq2_GR-caption',\n",
      "#  'seq2_GR-Interactions',\n",
      "#  'seq2_GR-HintText',\n",
      "#  'seq2_GR-Progress',\n",
      "#  'seq2_Interactions-Progress',\n",
      "# #  'seq2_Interactions-HintText',\n",
      "# #  'seq3_betweenGRs',\n",
      "#  'seq3_autoGR', #\n",
      "#  'seq3_GR-caption-GR',\n",
      "#  'seq3_caption-GR-caption',\n",
      "# #  'seq3_GR-Interactions-GR',\n",
      "#  'seq3_Interactions-GR-Interactions',\n",
      "#  'seq3_GR-HintText-GR',\n",
      "#  'seq3_HintText-GR-HintText',\n",
      "#  'seq3_Interactions-HintText-Interactions',\n",
      "#  'seq3_HintText-Interactions-HintText',\n",
      "#  'seq3_GR-Progress-GR',\n",
      "#  'seq3_Progress-GR-Progress',\n",
      "#  'seq3_Progress-Interactions-Progress',\n",
      "#  'pretest_sense',\n",
      "# #  'posttest1_sense',\n",
      "# #  'posttest2_sense',\n",
      "#  'pretest_fluency',\n",
      "# #  'posttest1_fluency',\n",
      "# #  'posttest2_fluency',\n",
      "#  'pretest_concScales',\n",
      "# #  'posttest1_concScales',\n",
      "# #  'posttest2_concScales',\n",
      "# #  'prePost_concScales',\n",
      "#  'Average_Pupil_Diameter_mm',\n",
      "#  'AveragePupil_Size_px_X']\n",
      "\n",
      "\n",
      "# df_rf_features = df_all_data[rf_feature_cols + list(problems) + list(students) + list(prob_types)]\n",
      "\n",
      "\n",
      "# # # Feature Importance with Random Forest / ExtraTreesClassifier and Cross-Validation\n",
      "# # importance_dict = defaultdict(list)\n",
      "# # for train_idx, cv_idx in KFold(n=len(df_rf_features), n_folds=12, indices=False, shuffle=True):\n",
      "# #     train_features = df_rf_features[train_idx]\n",
      "# #     train_y = np.asarray(df_all_data[train_idx][outcome_col])\n",
      "# #     test_features  = df_rf_features[cv_idx]\n",
      "# #     test_y = np.asarray(list(df_all_data[cv_idx][outcome_col]))\n",
      "\n",
      "# #     importances = clf.feature_importances_\n",
      "# #     for col, importance in zip(rf_feature_cols, importances):    \n",
      "# #         importance_dict[col].append(importance)\n",
      "\n",
      "# # # means are all pretty much the same between folds of a feature\n",
      "# # # [np.mean(importance_dict.values()) for key in importance_dict]\n",
      "\n",
      "# # sorted([(i ,importance_dict[i][0]) for i in importance_dict], key=lambda x: x[1], reverse=True)\n",
      "\n",
      "# # print [np.var(importance_dict[i]) for i in importance_dict]\n",
      "# #         if (importance > .03):\n",
      "# #             print col, importance\n",
      "        \n",
      "# #     print len([i for i in importances if i < .01])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rf_feature_cols = [\n",
      "#  'logs_Correct',\n",
      "#  'eye_fixDur_WhiteSpace',\n",
      "#  'eye_fixDur_Progress',\n",
      "#  'seq3_HintText-GR-HintText',\n",
      "#  'seq3_HintText-Interactions-HintText',\n",
      "#  'eye_2ndFixDur_Titles',\n",
      "#  'seq2_GR-caption',\n",
      "#  'eye_1stFixDur_Hints',\n",
      "#  'eye_2ndFixDur_GR',\n",
      "#  'seq3_GR-caption-GR',\n",
      "#  'eye_switch',\n",
      "#  'eye_fixDur_Interactions',\n",
      "#  'seq3_Progress-GR-Progress',\n",
      "#  'eye_fixDur_GR',\n",
      "#  'seq2_GR-Interactions',\n",
      "#  'eye_fixDur_Titles',\n",
      "#  'seq2_Interactions-Progress',\n",
      "#  'eye_1stFixDur_GR',\n",
      "#  'seq2_autoGR',\n",
      "#  'eye_1stFixDur_WhiteSpace',\n",
      "#  'eye_1stFixDur_Interactions',\n",
      "#  'eye_1stFixDur_Progress',\n",
      "#  'eye_2ndFixDur_Progress']\n",
      "\n",
      "# df_rf_features = df_all_data[rf_feature_cols + list(students)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}